## ğŸ§  TÃ­tulo del Proyecto

# AnÃ¡lisis Predictivo del Periodo de DiagnÃ³stico de CÃ¡ncer (WIDS Datathon 2024)

> Repositorio de Machine Learning modular para la clasificaciÃ³n del tiempo de diagnÃ³stico de cÃ¡ncer de mama (DiagPeriodL90D).

---

## ğŸ¯ Objetivo del Proyecto

El objetivo principal de este proyecto es construir y evaluar un **modelo de clasificaciÃ³n binaria** capaz de predecir si un paciente recibirÃ¡ un diagnÃ³stico de cÃ¡ncer de mama **rÃ¡pido** (en menos de 90 dÃ­as, `DiagPeriodL90D` = 1) o **lento** (en 90 dÃ­as o mÃ¡s, `DiagPeriodL90D` = 0), basÃ¡ndose en datos sociodemogrÃ¡ficos, clÃ­nicos y medioambientales.

La mÃ©trica de evaluaciÃ³n principal es el **Ã¡rea bajo la curva ROC (ROC-AUC)**, medida mediante validaciÃ³n cruzada.

---

## ğŸ—ï¸ Arquitectura del Proyecto (Estructura Modular)

Este repositorio sigue una arquitectura modular para separar claramente las responsabilidades, aplicar buenas prÃ¡cticas de desarrollo y facilitar la trazabilidad con MLflow.

Topicos2_Actividad2/
â”œâ”€â”€ data/           # Contiene los datasets originales (training.csv, test.csv)
â”œâ”€â”€ src/            # MÃ³dulos Python con la lÃ³gica de negocio
â”‚   â”œâ”€â”€ main.py     # Orquesta el pipeline completo.
â”‚   â”œâ”€â”€ module_data.py # Clase para carga, Feature Engineering y preprocesamiento (ColumnTransformer).
â”‚   â”œâ”€â”€ module_ml.py   # Clase para entrenamiento, evaluaciÃ³n (CV) y logging con MLflow.
â”‚   â””â”€â”€ module_path.py # Utilitario para manejo de rutas de archivos.
â””â”€â”€ mlruns/         # Directorio de tracking de MLflow.
â””â”€â”€ README.md

## âš™ï¸ Pipeline de Preprocesamiento (`module_data.py`)

El mÃ³dulo `module_data.py` ejecuta un **pipeline consistente y coherente** en ambos datasets (Training y Test) para asegurar la compatibilidad dimensional y prevenir la fuga de datos (data leakage).

### 1. IngenierÃ­a de CaracterÃ­sticas (Feature Engineering)
* **BMI:** La variable numÃ©rica `bmi` (con alta tasa de nulos) fue transformada en la variable categÃ³rica **`bmi_category`** (ej., `Normal`, `Unknown`). Esto permite capturar el valor predictivo de la falta de informaciÃ³n.
* **ImputaciÃ³n CategÃ³rica ExplÃ­cita:** Los nulos en `patient_race` y `payer_type` fueron imputados con la categorÃ­a **'Unknown'** o **'missing'**.
* **EliminaciÃ³n:** Se eliminÃ³ la columna numÃ©rica original `bmi` y otras columnas de ID/descripciÃ³n irrelevantes.

### 2. Transformaciones de Consistencia (ColumnTransformer)
Se utiliza un **`ColumnTransformer`** (entrenado solo con el set de entrenamiento) para aplicar las siguientes reglas:
* **Variables NumÃ©ricas:** ImputaciÃ³n de nulos por la media (`SimpleImputer`) seguida de **EstandarizaciÃ³n (`StandardScaler`)**.
* **Variables CategÃ³ricas:** **One-Hot Encoding** con la configuraciÃ³n clave **`handle_unknown='ignore'`** para manejar de forma segura las categorÃ­as presentes solo en el set de prueba y mantener las 237 caracterÃ­sticas consistentes.

---

## ğŸ§ª Resultados de la ExperimentaciÃ³n (MLflow Tracking)

Se evaluaron 6 modelos de clasificaciÃ³n utilizando **ValidaciÃ³n Cruzada (K=5 folds)**, y se compararon en mÃ©tricas de rendimiento y eficiencia.

| Modelo | ROC-AUC (Promedio CV) | Desv. EstÃ¡ndar | Tiempo (Segundos) | Conclusiones |
| :--- | :--- | :--- | :--- | :--- |
| **RegresiÃ³n LogÃ­stica** | **0.7946** | 0.0046 | 5.30 | **Mejor Rendimiento**. Alto poder predictivo lineal. |
| Random Forest | 0.7828 | 0.0077 | 21.10 | SÃ³lido rendimiento, pero mayor coste computacional. |
| GaussianNB (Naive Bayes) | 0.7511 | 0.0042 | **0.49** | **MÃ¡s Eficiente**. Excelente velocidad para un rendimiento aceptable. |
| Ãrbol de DecisiÃ³n | 0.7503 | 0.0088 | 4.23 | Base de rendimiento no lineal. |
| MLPClassifier | 0.7388 | 0.0068 | 97.90 | Rendimiento bajo para su complejidad y tiempo de cÃ³mputo. |
| KNeighborsClassifier | 0.6108 | 0.0059 | 6.62 | El rendimiento mÃ¡s bajo; sugiere que las clases no son localmente separables. |

### Conclusiones de Modelado

1.  **Modelo Base Ganador:** La **RegresiÃ³n LogÃ­stica** es el modelo base con el mejor balance ROC-AUC/eficiencia, lo que sugiere que la relaciÃ³n entre las variables y el diagnÃ³stico es predominantemente lineal.
2.  **Siguiente Paso:** Se requiere el **ajuste fino de hiperparÃ¡metros (Tuning)**, enfocado en el Random Forest y la RegresiÃ³n LogÃ­stica, para mejorar el ROC-AUC y optimizar la predicciÃ³n final.

---

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### 1. Requisitos de LibrerÃ­as

Instala todas las dependencias del proyecto:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn mlflow